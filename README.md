This repo started as an exercise to write an inference engine to [OLMo 2 1B](https://huggingface.co/allenai/OLMo-2-0425-1B) in pure C++.
C++ sure has changed since it was my main language...

Since I wanted to learn, the core model code is not written with any LLM help.
However, I let Claude optimize it afterwards, and after some encouragement it is now faster than PyTorch on CPU.
